{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers torch\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install transformers datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:04:04.424454Z","iopub.execute_input":"2024-06-25T12:04:04.425267Z","iopub.status.idle":"2024-06-25T12:04:18.503896Z","shell.execute_reply.started":"2024-06-25T12:04:04.425231Z","shell.execute_reply":"2024-06-25T12:04:18.502763Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq\nfrom datasets import load_dataset, load_metric\n\n# Load the dataset\ndataset = load_dataset(\"Kaludi/Customer-Support-Responses\")\n\n# Create train-test split\ndataset = dataset[\"train\"].train_test_split(test_size=0.2)  # 80% train, 20% test\n\n# Load the tokenizer and model\nmodel_name = \"t5-small\"  # You can use 't5-small', 't5-base', 't5-large', etc.\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\n# Preprocess the data\ndef preprocess_function(examples):\n    inputs = [\"summarize: \" + doc for doc in examples[\"query\"]]\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n\n    # Set up the tokenizer for targets\n    labels = tokenizer(examples[\"response\"], max_length=128, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess_function, batched=True)\n\n# Data collator\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\n# Set training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",  # Ensure save strategy matches evaluation strategy\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_total_limit=2,\n    load_best_model_at_end=True,\n)\n\n# Define the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    data_collator=data_collator,\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate the model\neval_results = trainer.evaluate()\nprint(f\"Evaluation results: {eval_results}\")\n\n# Save the model\nmodel.save_pretrained(\"./trained_model\")\ntokenizer.save_pretrained(\"./trained_model\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:43:03.033763Z","iopub.execute_input":"2024-06-26T15:43:03.034752Z","iopub.status.idle":"2024-06-26T15:43:12.697622Z","shell.execute_reply.started":"2024-06-26T15:43:03.034716Z","shell.execute_reply":"2024-06-26T15:43:12.696398Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/59 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16ca906fd9374b1f894ef0be1e944c17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033185b5ebf341b4b9228aed6570f4bb"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 00:05, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>3.180034</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>3.079034</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>3.041817</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/2 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation results: {'eval_loss': 3.0418174266815186, 'eval_runtime': 0.0616, 'eval_samples_per_second': 243.44, 'eval_steps_per_second': 32.459, 'epoch': 3.0}\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('./trained_model/tokenizer_config.json',\n './trained_model/special_tokens_map.json',\n './trained_model/spiece.model',\n './trained_model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"Kaludi/Customer-Support-Responses\")\n\n# Split dataset into train and test manually\ntrain_dataset = dataset[\"train\"].train_test_split(test_size=0.2)[\"train\"]\ntest_dataset = dataset[\"train\"].train_test_split(test_size=0.2)[\"test\"]\n\n# Load tokenizer and model (using t5-base for larger capacity)\nmodel_name = \"t5-base\"\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\n# Preprocess function with data augmentation\ndef preprocess_function(examples):\n    inputs = [\"summarize: \" + doc for doc in examples[\"query\"]]\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n\n    # Set up the tokenizer for targets\n    labels = tokenizer(examples[\"response\"], max_length=128, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n# Tokenize datasets with data augmentation\ntrain_tokenized_dataset = train_dataset.map(preprocess_function, batched=True)\ntest_tokenized_dataset = test_dataset.map(preprocess_function, batched=True)\n\n# Data collator\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\n# Training arguments with hyperparameter tuning\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=1e-4,  # Adjusted learning rate\n    per_device_train_batch_size=16,  # Increased batch size for larger model\n    per_device_eval_batch_size=16,\n    num_train_epochs=5,  # Increased epochs for potentially better convergence\n    weight_decay=0.01,\n    save_total_limit=2,\n    load_best_model_at_end=True,\n)\n\n# Trainer configuration\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tokenized_dataset,\n    eval_dataset=test_tokenized_dataset,\n    data_collator=data_collator,\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate the model\neval_results = trainer.evaluate()\nprint(f\"Evaluation results: {eval_results}\")\n\n# Save the model and tokenizer\nmodel.save_pretrained(\"./fine_tuned_model\")\ntokenizer.save_pretrained(\"./fine_tuned_model\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:01:48.925530Z","iopub.execute_input":"2024-06-26T16:01:48.926517Z","iopub.status.idle":"2024-06-26T16:02:40.303507Z","shell.execute_reply.started":"2024-06-26T16:01:48.926485Z","shell.execute_reply":"2024-06-26T16:02:40.302475Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f984849680ec48ba95409444476d2bd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05c92a8288d54ec8b7ebbb06f1635881"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfb96163b118468592c4682ceefd079e"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0443891a1c649d6a69b5aeb69849331"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"780aa0327d0648469ba147b4f85be43a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/59 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17d28b5997ea49e0a5e9c72e731240e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d17d1db51ac44e19a756c2911e426670"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 00:41, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.784467</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.462700</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.271467</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.162289</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.123368</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation results: {'eval_loss': 1.1233675479888916, 'eval_runtime': 0.0551, 'eval_samples_per_second': 272.397, 'eval_steps_per_second': 18.16, 'epoch': 5.0}\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_model/tokenizer_config.json',\n './fine_tuned_model/special_tokens_map.json',\n './fine_tuned_model/spiece.model',\n './fine_tuned_model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\n\ndef generate_response(query, model_path=\"./fine_tuned_model\"):\n    # Load tokenizer and model from the specified directory\n    tokenizer = T5Tokenizer.from_pretrained(model_path)\n    model = T5ForConditionalGeneration.from_pretrained(model_path)\n\n    # Tokenize the input query\n    inputs = tokenizer(\"summarize: \" + query, return_tensors=\"pt\")\n\n    # Generate response\n    outputs = model.generate(inputs.input_ids)\n\n    # Decode and return the response as a string\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# Example usage:\nquery = \"I'm having trouble applying a promo code.\"\nresponse = generate_response(query)\nprint(\"Generated Response:\")\nprint(response)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:05:22.354340Z","iopub.execute_input":"2024-06-26T16:05:22.354760Z","iopub.status.idle":"2024-06-26T16:05:24.144057Z","shell.execute_reply.started":"2024-06-26T16:05:22.354729Z","shell.execute_reply":"2024-06-26T16:05:24.142465Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Generated Response:\nWe're sorry to hear that. Can you please provide your promo code and the promo code\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}